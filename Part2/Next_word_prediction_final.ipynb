{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter Notebook file implements a simple next-word prediction model using a recurrent neural network (LSTM) with Keras and TensorFlow. Here is a step-by-step explanation for each cell:"
      ],
      "metadata": {
        "id": "2APQzlVPezKp"
      },
      "id": "2APQzlVPezKp"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cf1a8e96",
      "metadata": {
        "id": "cf1a8e96"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding, InputLayer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a64d99",
      "metadata": {
        "id": "a5a64d99"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"train.csv\")\n",
        "# len(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/CostiCTI/CourseML/refs/heads/main/Part2-Models/train.csv\")"
      ],
      "metadata": {
        "id": "d3YkogtD1mmK"
      },
      "id": "d3YkogtD1mmK",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZFEa2yrqfDHx",
        "outputId": "4b942ec4-f4be-4991-9c71-9cbcf3fe8663"
      },
      "id": "ZFEa2yrqfDHx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                               text  label\n",
              "0      0  acest document mi-a deschis cu adevarat ochii ...      1\n",
              "1      1  tine mancarea rece. ce altceva ii mai trebuie?...      1\n",
              "2      2                                excelent\\nrecomand!      1\n",
              "3      3  ca un rocker imbatranit, acest film mentioneaz...      1\n",
              "4      4  ei bine, a facut o groaza veche si foarte intu...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dda81051-08ca-4d13-aed3-9aebd144d410\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>acest document mi-a deschis cu adevarat ochii ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>tine mancarea rece. ce altceva ii mai trebuie?...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>excelent\\nrecomand!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ca un rocker imbatranit, acest film mentioneaz...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ei bine, a facut o groaza veche si foarte intu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dda81051-08ca-4d13-aed3-9aebd144d410')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dda81051-08ca-4d13-aed3-9aebd144d410 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dda81051-08ca-4d13-aed3-9aebd144d410');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f14d90af-2fa7-4406-931d-c30ec40ed098\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f14d90af-2fa7-4406-931d-c30ec40ed098')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f14d90af-2fa7-4406-931d-c30ec40ed098 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17941,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2982,\n        \"min\": 0,\n        \"max\": 11093,\n        \"num_unique_values\": 11094,\n        \"samples\": [\n          1891,\n          9166,\n          5909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16552,\n        \"samples\": [\n          \"nightmare weekend interpreteaza o aventura de actori ridicol, cu o idee mai putin despre ceea ce se intampla decat cu directorul, daca va puteti imagina acest lucru. nu exista un complot sau o poveste descifrabila, efectele speciale sunt o gluma si chiar sunetul este teribil. acest film a fost regizat de henry sala. a fost singurul film pe care la dirijat vreodata, iar motivul este evident.\",\n          \"rudy o face din nou cu acest cald de pe strazi urmand pana la dolemite. aceasta intrare este plina de racheta, umorul si artele martiale de la rudy ray moore. rudy evita un serif nebun de gat rosu in acest film, care are, de asemenea, o scena infama in care rudy scufunda pe un deal abrupt. vedeti-o pentru rade si pentru o lovitura de suflare a magiei blaxploitation.\",\n          \"nu stiu ce ziceti voi, dar filmul asta merita vazut....un film de calitate(printre putinele filme bune ale anului)...si asta este doar inceputul a ceva mult mai interesant si captivant, nu stiu, are ceva din seria cantec de gheata si foc...poate lupta noastra impotriva sistemului il face atat de atragator\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'text' column from the DataFrame df is extracted and converted into a Python list called data. This data list will be the text source for training the next word prediction model."
      ],
      "metadata": {
        "id": "1Bn24HJqfsiv"
      },
      "id": "1Bn24HJqfsiv"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a525494b",
      "metadata": {
        "id": "a525494b"
      },
      "outputs": [],
      "source": [
        "data = list(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "GxnyVjQh4Khs",
        "outputId": "c6e4ac67-90b9-4d18-f131-0c3baa463ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "id": "GxnyVjQh4Khs",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acest document mi-a deschis cu adevarat ochii la ceea ce oamenii din afara statelor unite s-au gandit la atacurile din 11 septembrie. acest film a fost construit in mod expert si prezinta acest dezastru ca fiind mai mult decat un atac asupra pamantului american. urmarile acestui dezastru sunt previzionate din multe tari si perspective diferite. cred ca acest film ar trebui sa fie mai bine distribuit pentru acest punct. de asemenea, el ajuta in procesul de vindecare sa vada in cele din urma altceva decat stirile despre atacurile teroriste. si unele dintre piese sunt de fapt amuzante, dar nu abuziv asa. acest film a fost extrem de recomandat pentru mine, si am trecut pe acelasi sentiment.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines a function called generate_subsentences.\n",
        "It takes a list of sentences as input.\n",
        "For each sentence:\n",
        "- It creates a translator to replace all punctuation characters with spaces.\n",
        "- It cleans the sentence using translate().\n",
        "- It splits the cleaned sentence into words.\n",
        "- Generates sub-sentences (n-grams) of length 2, 3, and 4 from these words and adds them to the result list.\n",
        "- It also adds a special case \"start\" to help predict the first word in a new sequence.\n",
        "- The try-except block handles any errors in processing a sentence.\n",
        "- The function returns a list of sub-sentences. These sub-sentences will be used to create input-output pairs for the model."
      ],
      "metadata": {
        "id": "LYcWS68cf2Q0"
      },
      "id": "LYcWS68cf2Q0"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f8937d1f",
      "metadata": {
        "id": "f8937d1f"
      },
      "outputs": [],
      "source": [
        "def generate_subsentences(sentences: list[str]) -> list[str]:\n",
        "    result = []\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    for sentence in sentences:\n",
        "        try:\n",
        "            clean_sentence = sentence.translate(translator)\n",
        "            words = clean_sentence.split()\n",
        "            for length in range(2, 5):\n",
        "                for start in range(len(words) - length + 1):\n",
        "                    subsentence = ' '.join(words[start:start + length])\n",
        "                    result.append(subsentence)\n",
        "            result.append(\"<start>\" + \" \" + sentence.split(\" \")[0])\n",
        "        except:\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "#sentences = [\"the cat sat on the table\", \"i like it\"]\n",
        "#print(generate_subsentences(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "559c5049",
      "metadata": {
        "id": "559c5049",
        "outputId": "593c99ad-d9ca-4d0f-9f83-853940a21f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4090603\n"
          ]
        }
      ],
      "source": [
        "props = generate_subsentences(data)\n",
        "print (len(props))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9d7dfc4b",
      "metadata": {
        "id": "9d7dfc4b"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7050524f",
      "metadata": {
        "id": "7050524f",
        "outputId": "1205d559-3d19-47f9-f0e7-7b3aac086733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cu actori de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "props[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "68772c72",
      "metadata": {
        "id": "68772c72",
        "outputId": "11fb7cec-f0d7-4656-8515-bb4c4bf9196c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500000\n"
          ]
        }
      ],
      "source": [
        "props = props[:500000]\n",
        "print (len(props))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines a constant NO_WORDS at 2000. This will be the maximum vocabulary size that the Tokenizer will use. Words that appear less frequently and do not fall within this NO_WORDS top will be treated as \"out-of-vocabulary\" (OVS)."
      ],
      "metadata": {
        "id": "Y10nBlm0gntu"
      },
      "id": "Y10nBlm0gntu"
    },
    {
      "cell_type": "code",
      "source": [
        "NO_WORDS = 2000"
      ],
      "metadata": {
        "id": "fut5ou0gEswL"
      },
      "id": "fut5ou0gEswL",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d08d3b13",
      "metadata": {
        "id": "d08d3b13"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=NO_WORDS, oov_token='unktoken')\n",
        "tokenizer.fit_on_texts(props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "10bf318c",
      "metadata": {
        "id": "10bf318c",
        "outputId": "ffef601a-1557-486e-90c2-5519d3b5aad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43775"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(tokenizer.index_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9b4fe366",
      "metadata": {
        "id": "9b4fe366",
        "outputId": "07ecfc57-8564-4a08-bcbe-5cc6c28e95e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unktoken'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tokenizer.index_word[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.index_word"
      ],
      "metadata": {
        "id": "ljhkf3U7E1nk"
      },
      "id": "ljhkf3U7E1nk",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell creates a list called oftenit that contains only words whose index is less than or equal to NO_WORDS. This should be equivalent to the actual vocabulary that the model will use (excluding OOV words, which are all mapped to a single index, 1). Then, it displays the length of this list. It should be equal to NO_WORDS."
      ],
      "metadata": {
        "id": "XvSnmWBYjJZs"
      },
      "id": "XvSnmWBYjJZs"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "390a6b5e",
      "metadata": {
        "id": "390a6b5e",
        "outputId": "d829df01-dbd4-47f8-dc0a-dc84aca49249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "oftenit = []\n",
        "for k, v in tokenizer.index_word.items():\n",
        "    if k <= NO_WORDS:\n",
        "        oftenit.append(v)\n",
        "print (len(oftenit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3e7ff849",
      "metadata": {
        "id": "3e7ff849",
        "outputId": "48bb0168-de10-4eec-87d0-16eb892ddc1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(oftenit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f052233a",
      "metadata": {
        "id": "f052233a"
      },
      "outputs": [],
      "source": [
        "#tokenizer.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9c3c42e0",
      "metadata": {
        "id": "9c3c42e0",
        "outputId": "1f19257e-0e80-417c-bc17-814c81b8c0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bolnave ei'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "props[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer.texts_to_sequences(props) converts each sub-sentence in props into a sequence of integers, where each number represents the index of the corresponding word in the tokenizer's vocabulary. Words that are not in the top NO_WORDS will be mapped to the oov_token index (which is 1)."
      ],
      "metadata": {
        "id": "AP-SgxTbjQ-V"
      },
      "id": "AP-SgxTbjQ-V"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fa6e5c30",
      "metadata": {
        "id": "fa6e5c30"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7b73a200",
      "metadata": {
        "id": "7b73a200",
        "outputId": "6c8be632-2524-4046-d576-94a44ad49b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 68]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "sequences[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "04391762",
      "metadata": {
        "id": "04391762",
        "outputId": "b22bbcb4-ca08-4967-ff13-b5463a6eed89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 20, 419]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "sequences[124]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell filters the sequences list.\n",
        "- Sequences that are longer than 4 or whose last word is oov_token (index 1) are ignored.\n",
        "- Only sequences that are at most 4 long and whose last word is NOT oov_token are added to the new xsequences list.\n",
        "- The motivation for len(seq) > 4 is that the model will use a 3-word input window to predict the 4th word. Also, ignoring sequences that end with oov_token (1) makes sense, because predicting an unknown word is not useful in this context."
      ],
      "metadata": {
        "id": "j9QuzAEQiEP6"
      },
      "id": "j9QuzAEQiEP6"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "24b5fedf",
      "metadata": {
        "id": "24b5fedf",
        "outputId": "12826f51-0a98-4961-86e4-4f7c2b4fb695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410223\n"
          ]
        }
      ],
      "source": [
        "xsequences = []\n",
        "for seq in sequences:\n",
        "    if len(seq) > 4 or seq[-1] == 1:\n",
        "        pass\n",
        "    else:\n",
        "        xsequences.append(seq)\n",
        "print (len(xsequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pad_sequences from tensorflow.keras.preprocessing.sequence: A utility to pad sequences to a uniform length (in this case, it will be 4, since we filtered out sequences longer than 4).\n",
        "- tensorflow as tf: Imports TensorFlow.\n",
        "- padded = pad_sequences(xsequences, padding=‘pre’): Pad the sequences in xsequences by adding zeros before the sequences so that they are all the same length. The maximum length of the sequences in xsequences is 4, so all shorter sequences will be padded to 4."
      ],
      "metadata": {
        "id": "1eRGfpx2jwLd"
      },
      "id": "1eRGfpx2jwLd"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b714d14c",
      "metadata": {
        "id": "b714d14c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "\n",
        "padded = pad_sequences(xsequences, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a5071eb4",
      "metadata": {
        "id": "a5071eb4",
        "outputId": "ddb91e76-662e-4e54-b123-899f49021c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0, 655,   5], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "padded[124]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "254cede6",
      "metadata": {
        "id": "254cede6",
        "outputId": "bbe1fb58-1d8f-44bf-f087-f1333db9eb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0 196  13]\n",
            "[ 3  1  1 28]\n",
            "[  0   0 655   5]\n"
          ]
        }
      ],
      "source": [
        "print (padded[32])\n",
        "print (padded[100])\n",
        "print (padded[124])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "13766af9",
      "metadata": {
        "id": "13766af9",
        "outputId": "4815fcd9-482f-4593-c98f-fdbb69cb2932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "410223"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- X, y = padded[:,:-1], padded[:,-1]: This splits the padded array into input (X) and output/label (y) sets.\n",
        "  - X: Contains all columns in padded except the last column. These are the input words for prediction (context). The length will be 3.\n",
        "  - y: Contains only the last column of padded. This is the target word (the next word to be predicted).\n",
        "- y = to_categorical(y, num_classes=NO_WORDS + 1): Converts the label vector y to one-hot encoding format. num_classes=NO_WORDS + 1 ensures that a class is assigned to each of the NO_WORDS words and one to oov_token."
      ],
      "metadata": {
        "id": "sVwWZnZjkAJ_"
      },
      "id": "sVwWZnZjkAJ_"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "847fce8d",
      "metadata": {
        "id": "847fce8d"
      },
      "outputs": [],
      "source": [
        "X, y = padded[:,:-1], padded[:,-1]\n",
        "y = to_categorical(y, num_classes=NO_WORDS + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "309ddac7",
      "metadata": {
        "id": "309ddac7",
        "outputId": "ee9b66a5-0d8d-436a-9cb7-2c984285a7ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(350000, 3)\n",
            "(350000, 2001)\n",
            "(60223, 3)\n",
            "(60223, 2001)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train = X[:350000]\n",
        "X_test = X[350000:]\n",
        "y_train = y[:350000]\n",
        "y_test = y[350000:]\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Această funcție definește o metrică personalizată pentru Keras, numită top_3_accuracy.\n",
        "- Calculează dacă eticheta reală (y_true) se află printre primele 3 predicții cu cea mai mare probabilitate (y_pred) ale modelului.\n",
        "  - tf.cast(tf.argmax(y_true, axis=-1), tf.int32): Convertește etichetele one-hot (y_true) în etichete întregi.\n",
        "  - tf.math.top_k(y_pred, k=3).indices: Extrage indexurile (adică, ID-urile cuvintelor) celor mai probabile 3 predicții.\n",
        "  - tf.reduce_any(tf.equal(tf.expand_dims(y_true, -1), top_3), axis=-1): Verifică dacă eticheta reală este prezentă în aceste top 3 predicții.\n",
        "  - tf.reduce_mean(tf.cast(matches, tf.float32)): Calculează procentul de potriviri, adică acuratețea top-3."
      ],
      "metadata": {
        "id": "KihiQNfTkUzw"
      },
      "id": "KihiQNfTkUzw"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "285633a7",
      "metadata": {
        "id": "285633a7"
      },
      "outputs": [],
      "source": [
        "def top_3_accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)  # Convert one-hot to integer labels\n",
        "    top_3 = tf.math.top_k(y_pred, k=3).indices\n",
        "    matches = tf.reduce_any(tf.equal(tf.expand_dims(y_true, -1), top_3), axis=-1)\n",
        "    return tf.reduce_mean(tf.cast(matches, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c6d6c9e8",
      "metadata": {
        "id": "c6d6c9e8",
        "outputId": "a17eec5f-eb83-469c-a976-71bc860e95cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │        \u001b[38;5;34m16,008\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2001\u001b[0m)           │        \u001b[38;5;34m18,009\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,008</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2001</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,009</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,561\u001b[0m (135.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,561</span> (135.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,561\u001b[0m (135.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,561</span> (135.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(3, ), dtype=np.int32))\n",
        "model.add(Embedding(NO_WORDS + 1, 8, input_length=4))\n",
        "model.add(LSTM(8))\n",
        "model.add(Dense(NO_WORDS + 1, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fb09ba09",
      "metadata": {
        "id": "fb09ba09"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_3_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f11cd06d",
      "metadata": {
        "scrolled": true,
        "id": "f11cd06d",
        "outputId": "5d74422f-924d-468b-9e2e-f70d8b989220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - accuracy: 0.0550 - loss: 5.8858 - top_3_accuracy: 0.1231 - val_accuracy: 0.0801 - val_loss: 5.4755 - val_top_3_accuracy: 0.1829\n",
            "Epoch 2/4\n",
            "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3ms/step - accuracy: 0.0980 - loss: 5.3719 - top_3_accuracy: 0.1973 - val_accuracy: 0.1301 - val_loss: 5.1399 - val_top_3_accuracy: 0.2333\n",
            "Epoch 3/4\n",
            "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4ms/step - accuracy: 0.1372 - loss: 5.0779 - top_3_accuracy: 0.2429 - val_accuracy: 0.1522 - val_loss: 4.9931 - val_top_3_accuracy: 0.2545\n",
            "Epoch 4/4\n",
            "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - accuracy: 0.1532 - loss: 4.9450 - top_3_accuracy: 0.2611 - val_accuracy: 0.1573 - val_loss: 4.9195 - val_top_3_accuracy: 0.2635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e11be648560>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.fit(X_train, y_train, batch_size=16, epochs=4, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1fd2583b",
      "metadata": {
        "id": "1fd2583b",
        "outputId": "1d5049c4-397d-4267-e509-23cdc36ab474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1882/1882\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Această celulă procesează predicțiile:\n",
        "- reverse_word_map: Se creează un dicționar inversat care mapează indexurile numerice înapoi la cuvinte (de la tokenizer.word_index).\n",
        "- results, wordsr: Două liste goale pentru a stoca rezultatele.\n",
        "- Bucla iterează prin fiecare predicție (pred) din preds (care este un array de probabilități pentru toate cuvintele din vocabular pentru o singură intrare):\n",
        "  - ar = pred.argsort()[-3:][::-1]: Obține indexurile celor mai probabile 3 cuvinte. argsort() returnează indexurile care ar sorta array-ul, [-3:] ia ultimele 3 (care corespund celor mai mari probabilități), iar [::-1] le inversează pentru a obține ordinea descrescătoare a probabilităților.\n",
        "  - results.append([ar[0], ar[1], ar[2]]): Adaugă indexurile celor top 3 cuvinte prezise la lista results.\n",
        "  - wordsr.append([reverse_word_map[ar[0]], reverse_word_map[ar[1]], reverse_word_map[ar[2]]]): Converște indexurile înapoi la cuvinte folosind reverse_word_map și adaugă cuvintele prezise la lista wordsr."
      ],
      "metadata": {
        "id": "V1WQwqwDmURN"
      },
      "id": "V1WQwqwDmURN"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4b4035e9",
      "metadata": {
        "id": "4b4035e9"
      },
      "outputs": [],
      "source": [
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "results = []\n",
        "wordsr = []\n",
        "for pred in preds:\n",
        "    ar = pred.argsort()[-3:][::-1]\n",
        "    results.append([ar[0], ar[1], ar[2]])\n",
        "    wordsr.append([reverse_word_map[ar[0]], reverse_word_map[ar[1]], reverse_word_map[ar[2]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etichetele reale (y_test) sunt în format one-hot encoding. Această celulă le convertește înapoi la formatul de index întreg (adică, ID-ul cuvântului real) folosind np.argmax."
      ],
      "metadata": {
        "id": "VGWYnb2gmjSO"
      },
      "id": "VGWYnb2gmjSO"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c9062c0e",
      "metadata": {
        "id": "c9062c0e"
      },
      "outputs": [],
      "source": [
        "testy = [np.argmax(x) for x in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1ab4bca7",
      "metadata": {
        "id": "1ab4bca7",
        "outputId": "dc25a44e-41a7-4660-9e01-63091ca3f646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60223"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(testy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "ef3c90bb",
      "metadata": {
        "id": "ef3c90bb",
        "outputId": "9bd0a27e-19d7-4853-8a6d-6ea26b49f246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: 0.15733191637746377\n",
            "R2: 0.22111153545987414\n",
            "R3: 0.26347076698271427\n"
          ]
        }
      ],
      "source": [
        "acc1 = 0\n",
        "acc2 = 0\n",
        "acc3 = 0\n",
        "for i in range(len(results)):\n",
        "    if results[i][0] == testy[i]:\n",
        "        acc1 += 1\n",
        "    if testy[i] in results[i][:2]:\n",
        "        acc2 += 1\n",
        "    if testy[i] in results[i][:3]:\n",
        "        acc3 += 1\n",
        "print ('R1:', acc1 / len(testy))\n",
        "print ('R2:', acc2 / len(testy))\n",
        "print ('R3:', acc3 / len(testy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b6fc71",
      "metadata": {
        "id": "f8b6fc71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "19afd0d1",
      "metadata": {
        "id": "19afd0d1"
      },
      "outputs": [],
      "source": [
        "aux = \"salut ce faci\"\n",
        "example = \"imi place\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a1418eb3",
      "metadata": {
        "id": "a1418eb3",
        "outputId": "9f5c1154-25e6-4824-842c-c60b1b50c871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 25, 633], [102, 138]]\n"
          ]
        }
      ],
      "source": [
        "example_seq = tokenizer.texts_to_sequences([aux, example])\n",
        "print (example_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "ba77f548",
      "metadata": {
        "id": "ba77f548",
        "outputId": "4c168513-29d8-4756-b8df-810325ce42cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  1  25 633]\n",
            " [  0 102 138]]\n"
          ]
        }
      ],
      "source": [
        "example_padded = pad_sequences(example_seq, padding='pre')\n",
        "print (example_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "2d3fc237",
      "metadata": {
        "id": "2d3fc237",
        "outputId": "1c4a759e-aaaf-42c1-e5bb-e2d496977a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(example_padded)[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ZoJp4Tm4Iz",
        "outputId": "0a52233c-ec40-477d-a759-2709c50c0050"
      },
      "id": "K3ZoJp4Tm4Iz",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.3212276e-10, 8.2865576e-10, 5.8938868e-02, ..., 1.8583516e-05,\n",
              "       3.2859039e-05, 8.2878376e-10], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ada1d651",
      "metadata": {
        "id": "ada1d651"
      },
      "outputs": [],
      "source": [
        "ar = pred.argsort()[-3:][::-1]\n",
        "res = [ar[0], ar[1], ar[2]]\n",
        "words_pred = [reverse_word_map[ar[0]], reverse_word_map[ar[1]], reverse_word_map[ar[2]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "55c6153f",
      "metadata": {
        "id": "55c6153f",
        "outputId": "251fc6fe-61d3-431a-b9a1-2e8a4094e097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.int64(2), np.int64(7), np.int64(10)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "9c2d896a",
      "metadata": {
        "id": "9c2d896a",
        "outputId": "d796de92-2c62-4710-9cb3-fca7cf16a6f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de', 'sa', 'o']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "words_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4beaef60",
      "metadata": {
        "id": "4beaef60"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c35e707",
      "metadata": {
        "id": "9c35e707"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}